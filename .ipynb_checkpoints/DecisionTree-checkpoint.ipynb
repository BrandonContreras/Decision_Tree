{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal API of Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-ea7206607fc0>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ea7206607fc0>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    my_tree.score(X, y[, sample_weight]) # Return the mean accuracy on the given test data and labels.\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"file.csv\")\n",
    "train, test = train_test_split(df, test_size=0.2) # find actual one to use\n",
    "\n",
    "\n",
    "my_tree = DecisionTree()\n",
    "my_tree.fit(X, Y) # X being all data, Y being just labels for each sample\n",
    "my_tree.predict(X) #---> return an array of target labels for each i in X (find shape of X at first)\n",
    "my_tree.score(X, y[, sample_weight]) # Return the mean accuracy on the given test data and labels.\n",
    "\n",
    "my_tree.plot() # returns graph visual of nodes\n",
    "my_tree.depth() # return max depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notes:\n",
    "\n",
    "- How to handle a column that is not categorical? That is numerical\n",
    "- Create Method to determine type of column.\n",
    "- Change fit to take in X vectors and Y target vector\n",
    "- Convert to some other python tree for easy printing or something. Grahpical\n",
    "- Incorportate the Deku Tree for site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site Posting Notes:\n",
    "- Use stanford kids site as rough guide but make cooler with Guess who. Start with that.\n",
    "- Note I chose more verbose programming statements in key parts of the algorithm as 1. More clear what part of the algo I'm doing. This is for me to learn, explain, and for others to easily see. If this were production I would be more likely to use more efficient python one liners. Have an example of a crazy one liner of like gini impurity.\n",
    "\n",
    "- For each method, have latex like 436 of math algorithm.\n",
    "- Explain the complexities of category data from easy, medium, hard. one-hot, 2^n gini choices, word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    #  Class attribute. Same value for every instance of this class.\n",
    "    numMoney = 100000\n",
    "\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.gini = None\n",
    "        self.left_child = None \n",
    "        self.right_child = None\n",
    "        self.class_label = None \n",
    "        self.is_leaf = False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"NumSamples: {self.num_samples}\" \\\n",
    "        f\"\\nLabel: {self.class_label}\" \\\n",
    "        f\"\\nGini: {self.gini}\" \\\n",
    "        f\"\\nColumnToSplit: {self.split_feature}\" \\\n",
    "        f\"\\nSplitValue: {self.split_value}\" \\\n",
    "        f\"\\nLeaf: {self.is_leaf}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        self.root_node = None\n",
    "        self.num_nodes = 0\n",
    "        self.target_feature = None\n",
    "        self.max_depth = max_depth\n",
    "        self.node_count = 0\n",
    "\n",
    "    def predict(self, sample):\n",
    "        \"\"\"Predict the class label of the given sample.\"\"\"\n",
    "        node = self.root_node\n",
    "        \n",
    "        while(node.is_leaf == False):\n",
    "            \n",
    "            if sample[node.split_feature] == node.split_value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "        return node.class_label\n",
    "\n",
    "    def _gini(self, df):\n",
    "        \"\"\"Returns gini score of df\n",
    "        uses target_feature variable of tree to find score\n",
    "        takes in a DF right now.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        t = len(df)\n",
    "        p = df.groupby(self.target_feature).size() / t\n",
    "        return 1 - sum(p**2)\n",
    "\n",
    "    def _impurity(self, df, prop):\n",
    "        s = 0\n",
    "        for k, subf in df.groupby(prop):\n",
    "            g = self._gini(subf)\n",
    "\n",
    "            # Get weighted average of gini values for a whole columns different values.\n",
    "            s += g * (len(subf) / len(df))\n",
    "        return s\n",
    "\n",
    "    def _split_feature(self, df):\n",
    "        \"\"\"Find the best feature to split on given a df. Return column to split on\"\"\"\n",
    "        # make better with just two lists? or a list of lists?\n",
    "        col_scores = {}\n",
    "        data = df.drop(self.target_feature, axis=1)\n",
    "        # make iterative, just store a min_score value instead of a list. \n",
    "        for column in data.columns:\n",
    "            weighted_gini = self._impurity(df, column)\n",
    "            col_scores[column] = weighted_gini\n",
    "\n",
    "        # return col_scores\n",
    "        # return (min(col_scores, key=col_scores.get))\n",
    "\n",
    "        lowest_feature = min(col_scores, key=col_scores.get)\n",
    "        lowest_score = col_scores[lowest_feature]\n",
    "\n",
    "        return lowest_feature, lowest_score\n",
    "\n",
    "    def _split_value(self, df, feature):\n",
    "        \"\"\"Find the best value of a given feature to split on\"\"\"\n",
    "\n",
    "        values = {}\n",
    "        for k, subf in df.groupby(feature):\n",
    "            g = self._gini(subf)\n",
    "            # Weighted average of gini score.\n",
    "            values[k] = g * len(subf) / len(df)\n",
    "\n",
    "        # return values\n",
    "        # return value that has the lowest gini score\n",
    "        return (min(values, key=values.get))\n",
    "\n",
    "    def fit(self, df, target):\n",
    "        \"\"\"where target is string of target column to predict.\"\"\"\n",
    "        self.target_feature = target\n",
    "        root_node = DecisionNode(len(df))\n",
    "\n",
    "    def _build_tree(self, df):\n",
    "        self.root_node = DecisionNode(len(df))\n",
    "\n",
    "        # Recursively add nodes to tree\n",
    "        self._splitNode(df, self.root_node, 0)\n",
    "\n",
    "    def _splitNode(self, df, node, current_level):\n",
    "        \"\"\"Given a df, split that into two subframes based on the best gini-gain\"\"\"\n",
    "        self.node_count += 1\n",
    "\n",
    "        feature, feature_score = self._split_feature(df)\n",
    "        node.gini = self._gini(df)\n",
    "        node.class_label = df[self.target_feature].mode()[0]\n",
    "\n",
    "\n",
    "      #  weighted_impurity_decrease = (\n",
    "       #     node.num_samples / self.root_node.num_samples) * (node.gini - feature_score)\n",
    "\n",
    "        # if ((node.gini - feature_score) > self.threshold ):\n",
    "\n",
    "        # if(node.gini > feature_score):\n",
    "        if(current_level < self.max_depth):\n",
    "            current_level += 1\n",
    "\n",
    "            node.is_leaf = False\n",
    "            node.split_feature = feature\n",
    "            node.split_value = self._split_value(df, feature)\n",
    "\n",
    "            left_df = df[df[feature] == node.split_value]  # left == true\n",
    "            right_df = df[df[feature] != node.split_value]  # right == false\n",
    "            \n",
    "            if(len(left_df) > 0):\n",
    "                node.left_child = DecisionNode(len(left_df))\n",
    "                self._splitNode(left_df, node.left_child, current_level)\n",
    "            if(len(right_df) > 0):\n",
    "                node.right_child = DecisionNode(len(right_df))\n",
    "                self._splitNode(right_df, node.right_child, current_level)\n",
    "            return\n",
    "        else:\n",
    "            node.is_leaf = True\n",
    "            return\n",
    "\n",
    "    def score(self, test):\n",
    "        \"\"\"Return accuracy on given samples and labels\"\"\"\n",
    "        result = pd.Series(dtype=object)\n",
    "        results = test.apply(lambda x: True if x[self.target_feature] == self.predict(x) else False, axis=1)\n",
    "        score = ( results.value_counts()[True] / len(results) ) * 100\n",
    "        return score\n",
    "      \n",
    "\n",
    "    def print_nodes(self):\n",
    "        \"\"\"Print tree in level order\"\"\"\n",
    "        if self.root_node == None:\n",
    "            return\n",
    "\n",
    "        queue = deque()\n",
    "        queue.append(self.root_node)\n",
    "\n",
    "        while(len(queue) > 0):\n",
    "            node = queue.popleft()\n",
    "            print(node)\n",
    "\n",
    "            if node.left_child != None:\n",
    "                queue.append(node.left_child)\n",
    "            if node.right_child is not None:\n",
    "                queue.append(node.right_child)\n",
    "\n",
    "    # if category is numerical, split into quartiles, get scores of each chunk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CURRENT OBJECTIVE:\n",
    "- [x] Gini method with numpy DONE\n",
    "- [x] Impurity method with numpy done\n",
    "- [ ] Combine split_feature and split_value into a 3 tuple returning call\n",
    "  \n",
    "  \n",
    "# NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DecisionNode:\n",
    "    # need to have store indices of orginal DF\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.gini = None\n",
    "        self.left_child = None \n",
    "        self.right_child = None\n",
    "        self.class_label = None \n",
    "        self.is_leaf = False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"NumSamples: {self.num_samples}\" \\\n",
    "        f\"\\nLabel: {self.class_label}\" \\\n",
    "        f\"\\nGini: {self.gini}\" \\\n",
    "        f\"\\nColumnToSplit: {self.split_feature}\" \\\n",
    "        f\"\\nSplitValue: {self.split_value}\" \\\n",
    "        f\"\\nLeaf: {self.is_leaf}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        self.root_node = None\n",
    "        self.num_nodes = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.node_count = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Builds the decision tree from the given training samples and their \n",
    "        respective labels\n",
    "\n",
    "        : array X: An array of training input samples of shape(n_samples, n_features)\n",
    "        : array y: An array representing the labels for each sample of shape(n_samples)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Returns the gini score of the array \n",
    "        TODO: THIS WORKS. WAS TESTED.  \n",
    "        1 FEEDS TO IMPURITY NEXT ->\n",
    "\n",
    "        : array y: Array containing labels\n",
    "        \"\"\"\n",
    "        n = len(y)\n",
    "        # labels: array containing all unique labels in y\n",
    "        # freq: where freq[i] = frequency of lables[i]\n",
    "        labels, freq = np.unique(y, return_counts=True)\n",
    "\n",
    "        # prob: performs vector wise division. Is a vector\n",
    "        prob = freq / n\n",
    "\n",
    "        # Vector wise squaring of the probabilites\n",
    "        prob = prob**2\n",
    "        # Add them all up\n",
    "        sigma_prob = prob.sum()\n",
    "\n",
    "        gini = 1 - sigma_prob\n",
    "        return gini\n",
    "\n",
    "    # def numerical_impurity(split_feature, y_labels):\n",
    "    def category_impurity(self, split_feature, y_labels):\n",
    "        \"\"\"\n",
    "        WORKS AND TESTED\n",
    "        Finds the total gini impurity for a possible split on the given vector.\n",
    "\n",
    "        :np.array split_feature: Vector of categorical feature values\n",
    "        :np.array y_labels: Vector of labels corresponding to split_feature\n",
    "        \"\"\"\n",
    "        n = len(y_labels)\n",
    "        # If I divide x_feature column up into groups for each of its different values, what is the gini score for each one\n",
    "        total_impurity = 0\n",
    "\n",
    "        # All the unique values of the proposed feature column\n",
    "        feature_values = np.unique(split_feature)\n",
    "\n",
    "        # For each  unique value in the feature column, find the weighted gini impurity of dividing the sample space\n",
    "        # into groups of that value, return the total impurity for all groups.\n",
    "\n",
    "        for value in feature_values:\n",
    "            y_group = y_labels[np.where(split_feature == value)]\n",
    "\n",
    "            gini_val = self.gini_impurity(y_group)\n",
    "\n",
    "            weighted_impurity = gini_val * (len(y_group) / n)\n",
    "\n",
    "            total_impurity += weighted_impurity\n",
    "\n",
    "        return total_impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CURRENT METHOD WORKING ON\n",
    "* impurity for a numerical vector\n",
    "* have tree store y_labels in self. no need to keep passing every other call\n",
    "* Only pass the row indices of original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity_vector(self, x, y_labels):\n",
    "    \"\"\"\n",
    "    Find the best value within a feature vector to split on.\n",
    "    \"\"\"\n",
    "    # Sort values in ascending order\n",
    "    x.sort()\n",
    "    \n",
    "    # Compute the gini impurity for each in between average\n",
    "    \n",
    "    for i in range(1 : len(x)):\n",
    "        avg = x[i] + x[i - 1] / 2\n",
    "        # get gini score of the values below and values ABOVE the average. \n",
    "        # need y_labels that correspond to the x-vector values.\n",
    "        impurity = self.gini_impurity(y)\n",
    "        \n",
    "        #gini_impurity(self, y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Gain: 0.08333333333333348\n"
     ]
    }
   ],
   "source": [
    "x = np.array(['cat', 'cat', 'dog'])\n",
    "y = np.array([20, 30, 0])\n",
    "\n",
    "z = y[np.where(x == 'cat')]\n",
    "print(z)\n",
    "\n",
    "# TEST GINI-WEIGHTED IMPURITY\n",
    "initial = np.array(['red', 'red', 'red', 'blue', 'blue', 'blue', 'green', 'green', 'green'])\n",
    "data = np.array([1, 2, 2,2,2,2,2,2,2])\n",
    "total = gini_impurity(initial)\n",
    "\n",
    "possible = category_impurity(data, initial)\n",
    "\n",
    "print(f\"Gini Gain: {total - possible}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## documentation\n",
    "def test_function(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    test_function does blah blah blah.\n",
    "\n",
    "    :param p1: describe about parameter p1\n",
    "    :param p2: describe about parameter p2\n",
    "    :param p3: describe about parameter p3\n",
    "    :return: describe what it returns\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very good query, like sql\n",
    "df_low = df.loc[df[\"salary\"]<6000,\"salary\"]\n",
    "\n",
    "# Lambda usuage\n",
    "df['age']=df.apply(lambda x: x['age']+3,axis=1)\n",
    "\n",
    "#Get a single value. Goes [row][column]\n",
    "sub_df.iloc[0]['A']\n",
    "\n",
    "# lambda\n",
    "efficiency_df[\"Speed Multiplier\"] = efficiency_df.apply(lambda x: x[\"Time(s)\"] / efficiency_df.iloc[0][\"Time(s)\"], axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "397px",
    "left": "1098px",
    "right": "20px",
    "top": "119px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
